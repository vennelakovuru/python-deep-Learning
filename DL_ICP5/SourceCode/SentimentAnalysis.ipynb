{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiMb8bVY0DLn"
      },
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Il61tOOj0UHs"
      },
      "source": [
        "#Reading the dataset\n",
        "data = pd.read_csv('Sentiment.csv') \n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']] \n",
        "#converting to lower case\n",
        "data['text'] = data['text'].apply(lambda x: x.lower()) \n",
        "# Removing special characters from the data\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-Z0-9\\s]', '', x))) \n",
        "#Removing Retweets\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ') "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFEUH2X41GmK"
      },
      "source": [
        "#taking 2000 as max value to tokenize sentence\n",
        "max_fatures = 2000\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values) \n",
        "# values for feature matrix\n",
        "X = tokenizer.texts_to_sequences(data['text'].values) \n",
        "#Padding the feature matrix\n",
        "X = pad_sequences(X) \n",
        "embed_dim = 128 \n",
        "lstm_out = 196 "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcyMZI8f1UHH"
      },
      "source": [
        "#Defining function to create model using Sequential Neural Network\n",
        "def createmodel():\n",
        "    model = Sequential() \n",
        "    #taking input dimension 2000 Neurons, output dimension 128 Neurons\n",
        "    model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1])) \n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)) \n",
        "    #3 output neurons[positive, Neutral, Negative], softmax as activation\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    #Compiling the model\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) \n",
        "    return model\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA2Clmpw1ZKS"
      },
      "source": [
        "#Applying label Encoding\n",
        "labelencoder = LabelEncoder() \n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment']) \n",
        "y = to_categorical(integer_encoded)\n",
        "#Splitting data into 67% training data, 33% test data \n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVBT7Jqy1kB1",
        "outputId": "4496075d-4a81-48ec-b8da-d7ecb96e5b9a"
      },
      "source": [
        "# Model Creation\n",
        "batch_size = 32 \n",
        "#Function call to Sequential Neural Network\n",
        "model = createmodel() \n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) \n",
        "#model evaluation\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size) \n",
        "print(score)\n",
        "print(acc)\n",
        "print(model.metrics_names) #metrics of the model"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "291/291 - 43s - loss: 0.8261 - accuracy: 0.6412\n",
            "144/144 - 2s - loss: 0.7544 - accuracy: 0.6695\n",
            "0.7544063329696655\n",
            "0.669506311416626\n",
            "['loss', 'accuracy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EB0qTRQ_2m8"
      },
      "source": [
        "# 1. Save the model and use the saved model to predict on new text data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ_sc8zr1wrb",
        "outputId": "46aea44c-eee9-42bc-8a40-4a29d2854640"
      },
      "source": [
        "from keras.models import load_model \n",
        "\n",
        "#Saving the model\n",
        "model.save('sentimentAnalysis.h5') \n",
        "#loading the saved model\n",
        "model= load_model('sentimentAnalysis.h5') \n",
        "print(data['sentiment'])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BK1HShUD1_-G",
        "outputId": "6d72294a-d8cd-4aae-b4c3-33c290e4116c"
      },
      "source": [
        "#predicting on the text data\n",
        "textData = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "#tokenizing given textData\n",
        "sentence = tokenizer.texts_to_sequences(textData) \n",
        "#padding the tokenized sentence\n",
        "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0) \n",
        "#predicting the text\n",
        "sentimentPrediction = model.predict_classes(sentence,batch_size=1,verbose = 2)[0] \n",
        "if sentimentPrediction == 0:\n",
        "  print(\"Neutral\")\n",
        "elif sentimentPrediction < 0:\n",
        "  print(\"Negative\")\n",
        "elif sentimentPrediction > 0:\n",
        "  print(\"Positive\")\n",
        "else:\n",
        "  print(\"Can not be determined\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s\n",
            "Neutral\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cs-F_lFhwqP"
      },
      "source": [
        "# 2. Apply GridSearchCV on the source code provided in the class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6VO3VP-2KJi",
        "outputId": "1fec99e9-0b25-4360-c09f-c2045b2540a1"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#Applying multiple hyper parameters on the model\n",
        "model = KerasClassifier(build_fn=createmodel,verbose=2) \n",
        "#batch size\n",
        "batch_size= [10, 20, 40] \n",
        "#epochs\n",
        "epochs = [1, 2]\n",
        "param_grid= {'batch_size':batch_size, 'epochs':epochs} \n",
        "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result= grid.fit(X_train,Y_train) \n",
        "# summarizing results\n",
        "print(\"Best Score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "744/744 - 93s - loss: 0.8235 - accuracy: 0.6473\n",
            "186/186 - 2s - loss: 0.7492 - accuracy: 0.6783\n",
            "744/744 - 93s - loss: 0.8157 - accuracy: 0.6494\n",
            "186/186 - 2s - loss: 0.7965 - accuracy: 0.6643\n",
            "744/744 - 94s - loss: 0.8314 - accuracy: 0.6426\n",
            "186/186 - 2s - loss: 0.7709 - accuracy: 0.6783\n",
            "744/744 - 93s - loss: 0.8216 - accuracy: 0.6477\n",
            "186/186 - 2s - loss: 0.7385 - accuracy: 0.6814\n",
            "744/744 - 94s - loss: 0.8196 - accuracy: 0.6457\n",
            "186/186 - 2s - loss: 0.7726 - accuracy: 0.6658\n",
            "Epoch 1/2\n",
            "744/744 - 92s - loss: 0.8247 - accuracy: 0.6455\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6787 - accuracy: 0.7107\n",
            "186/186 - 2s - loss: 0.7520 - accuracy: 0.6837\n",
            "Epoch 1/2\n",
            "744/744 - 94s - loss: 0.8218 - accuracy: 0.6466\n",
            "Epoch 2/2\n",
            "744/744 - 92s - loss: 0.6834 - accuracy: 0.7137\n",
            "186/186 - 2s - loss: 0.7386 - accuracy: 0.6643\n",
            "Epoch 1/2\n",
            "744/744 - 93s - loss: 0.8199 - accuracy: 0.6484\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6718 - accuracy: 0.7174\n",
            "186/186 - 2s - loss: 0.7595 - accuracy: 0.6772\n",
            "Epoch 1/2\n",
            "744/744 - 93s - loss: 0.8248 - accuracy: 0.6444\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6712 - accuracy: 0.7166\n",
            "186/186 - 3s - loss: 0.7440 - accuracy: 0.6868\n",
            "Epoch 1/2\n",
            "744/744 - 92s - loss: 0.8199 - accuracy: 0.6448\n",
            "Epoch 2/2\n",
            "744/744 - 90s - loss: 0.6696 - accuracy: 0.7123\n",
            "186/186 - 2s - loss: 0.7671 - accuracy: 0.6706\n",
            "372/372 - 55s - loss: 0.8295 - accuracy: 0.6435\n",
            "93/93 - 2s - loss: 0.7394 - accuracy: 0.6638\n",
            "372/372 - 57s - loss: 0.8305 - accuracy: 0.6419\n",
            "93/93 - 2s - loss: 0.7679 - accuracy: 0.6719\n",
            "372/372 - 55s - loss: 0.8286 - accuracy: 0.6433\n",
            "93/93 - 2s - loss: 0.7578 - accuracy: 0.6778\n",
            "372/372 - 57s - loss: 0.8408 - accuracy: 0.6381\n",
            "93/93 - 2s - loss: 0.7477 - accuracy: 0.6668\n",
            "372/372 - 56s - loss: 0.8310 - accuracy: 0.6420\n",
            "93/93 - 2s - loss: 0.7694 - accuracy: 0.6658\n",
            "Epoch 1/2\n",
            "372/372 - 57s - loss: 0.8292 - accuracy: 0.6408\n",
            "Epoch 2/2\n",
            "372/372 - 54s - loss: 0.6828 - accuracy: 0.7070\n",
            "93/93 - 2s - loss: 0.7372 - accuracy: 0.6859\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8322 - accuracy: 0.6407\n",
            "Epoch 2/2\n",
            "372/372 - 54s - loss: 0.6868 - accuracy: 0.7020\n",
            "93/93 - 2s - loss: 0.7442 - accuracy: 0.6837\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8380 - accuracy: 0.6425\n",
            "Epoch 2/2\n",
            "372/372 - 54s - loss: 0.6819 - accuracy: 0.7046\n",
            "93/93 - 2s - loss: 0.7519 - accuracy: 0.6945\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8331 - accuracy: 0.6408\n",
            "Epoch 2/2\n",
            "372/372 - 53s - loss: 0.6780 - accuracy: 0.7093\n",
            "93/93 - 2s - loss: 0.7430 - accuracy: 0.6895\n",
            "Epoch 1/2\n",
            "372/372 - 56s - loss: 0.8228 - accuracy: 0.6448\n",
            "Epoch 2/2\n",
            "372/372 - 54s - loss: 0.6642 - accuracy: 0.7192\n",
            "93/93 - 2s - loss: 0.8124 - accuracy: 0.6399\n",
            "186/186 - 31s - loss: 0.8499 - accuracy: 0.6344\n",
            "47/47 - 1s - loss: 0.7595 - accuracy: 0.6654\n",
            "186/186 - 30s - loss: 0.8380 - accuracy: 0.6377\n",
            "47/47 - 1s - loss: 0.7985 - accuracy: 0.6584\n",
            "186/186 - 31s - loss: 0.8485 - accuracy: 0.6308\n",
            "47/47 - 1s - loss: 0.7711 - accuracy: 0.6751\n",
            "186/186 - 30s - loss: 0.8524 - accuracy: 0.6305\n",
            "47/47 - 1s - loss: 0.7550 - accuracy: 0.6798\n",
            "186/186 - 31s - loss: 0.8414 - accuracy: 0.6338\n",
            "47/47 - 1s - loss: 0.7754 - accuracy: 0.6712\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8505 - accuracy: 0.6324\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6898 - accuracy: 0.7063\n",
            "47/47 - 1s - loss: 0.7375 - accuracy: 0.6735\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8424 - accuracy: 0.6367\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6905 - accuracy: 0.7063\n",
            "47/47 - 1s - loss: 0.7404 - accuracy: 0.6789\n",
            "Epoch 1/2\n",
            "186/186 - 31s - loss: 0.8468 - accuracy: 0.6324\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6861 - accuracy: 0.7086\n",
            "47/47 - 1s - loss: 0.7399 - accuracy: 0.6912\n",
            "Epoch 1/2\n",
            "186/186 - 30s - loss: 0.8457 - accuracy: 0.6339\n",
            "Epoch 2/2\n",
            "186/186 - 28s - loss: 0.6873 - accuracy: 0.7054\n",
            "47/47 - 1s - loss: 0.7388 - accuracy: 0.6905\n",
            "Epoch 1/2\n",
            "186/186 - 30s - loss: 0.8519 - accuracy: 0.6335\n",
            "Epoch 2/2\n",
            "186/186 - 27s - loss: 0.6863 - accuracy: 0.7076\n",
            "47/47 - 1s - loss: 0.7968 - accuracy: 0.6722\n",
            "Epoch 1/2\n",
            "233/233 - 37s - loss: 0.8239 - accuracy: 0.6427\n",
            "Epoch 2/2\n",
            "233/233 - 35s - loss: 0.6791 - accuracy: 0.7128\n",
            "Best Score: 0.681265 using {'batch_size': 40, 'epochs': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}